{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74af1ea8-93e9-42f6-87e6-0426373a0d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_11812\\2233931995.py:28: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_11812\\2233931995.py:117: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(label=\"ServiceNow Assistant (CSV + RAG)\", height=500)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain + Chroma\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# --- Setup ---\n",
    "load_dotenv(override=True)\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n",
    "openai = OpenAI()\n",
    "embeddings = OpenAIEmbeddings()\n",
    "persist_dir = \"vector_db\"\n",
    "\n",
    "# Load Chroma DB\n",
    "db = Chroma(persist_directory=persist_dir, embedding_function=embeddings)\n",
    "\n",
    "# Setup Conversational RAG\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "rag_chain = ConversationalRetrievalChain.from_llm(\n",
    "    ChatOpenAI(model=\"gpt-4o-mini\"),\n",
    "    retriever=db.as_retriever(search_kwargs={\"k\": 3}),\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "# --- CSV Generator ---\n",
    "def generate_servicenow_data(n=10000):\n",
    "    np.random.seed(42)\n",
    "    random.seed(42)\n",
    "\n",
    "    priorities = [\"Low\", \"Medium\", \"High\", \"Critical\"]\n",
    "    impacts = [\"Low\", \"Medium\", \"High\"]\n",
    "    urgencies = [\"Low\", \"Medium\", \"High\"]\n",
    "    statuses = [\"Open\", \"In Progress\", \"Resolved\", \"Closed\"]\n",
    "    categories = [\"Network\", \"Software\", \"Hardware\", \"Database\", \"Security\"]\n",
    "    subcategories = {\n",
    "        \"Network\": [\"VPN\", \"LAN\", \"WAN\"],\n",
    "        \"Software\": [\"Email\", \"OS\", \"Application\"],\n",
    "        \"Hardware\": [\"Laptop\", \"Desktop\", \"Printer\"],\n",
    "        \"Database\": [\"Oracle\", \"MySQL\", \"SQL Server\"],\n",
    "        \"Security\": [\"Phishing\", \"Malware\", \"Access\"],\n",
    "    }\n",
    "    resolution_codes = [\"Solved Remotely\", \"Solved via On-Site\", \"Workaround Provided\", \"Not Reproducible\"]\n",
    "\n",
    "    opened_dates = pd.date_range(\"2025-07-01\", periods=n, freq=\"h\")\n",
    "    status_selected = np.random.choice(statuses, n, p=[0.3, 0.3, 0.2, 0.2])\n",
    "\n",
    "    closed_dates, resolution_codes_selected, resolved_by = [], [], []\n",
    "    for i, status in enumerate(status_selected):\n",
    "        if status in [\"Resolved\", \"Closed\"]:\n",
    "            closed_dt = opened_dates[i] + timedelta(hours=random.randint(1, 72))\n",
    "            closed_dates.append(closed_dt)\n",
    "            resolution_codes_selected.append(random.choice(resolution_codes))\n",
    "            resolved_by.append(f\"user{random.randint(401,600)}\")\n",
    "        else:\n",
    "            closed_dates.append(pd.NaT)\n",
    "            resolution_codes_selected.append(None)\n",
    "            resolved_by.append(None)\n",
    "\n",
    "    categories_selected = np.random.choice(categories, n)\n",
    "    subcategories_selected = [random.choice(subcategories[cat]) for cat in categories_selected]\n",
    "\n",
    "    data = {\n",
    "        \"Incident_ID\": [f\"INC{i:06d}\" for i in range(1, n+1)],\n",
    "        \"Opened_At\": opened_dates,\n",
    "        \"Closed_At\": closed_dates,\n",
    "        \"Opened_By\": [f\"user{random.randint(1,200)}\" for _ in range(n)],\n",
    "        \"Assigned_To\": [f\"user{random.randint(201,400)}\" for _ in range(n)],\n",
    "        \"Priority\": np.random.choice(priorities, n),\n",
    "        \"Impact\": np.random.choice(impacts, n),\n",
    "        \"Urgency\": np.random.choice(urgencies, n),\n",
    "        \"Category\": categories_selected,\n",
    "        \"Subcategory\": subcategories_selected,\n",
    "        \"Status\": status_selected,\n",
    "        \"Resolution_Code\": resolution_codes_selected,\n",
    "        \"Resolved_By\": resolved_by,\n",
    "        \"Short_Description\": [f\"Issue {i} - {random.choice(categories)} related\" for i in range(1, n+1)],\n",
    "        \"Description\": [f\"Detailed description of incident {i}, auto-generated for testing.\" for i in range(1, n+1)],\n",
    "        \"Updated_At\": [d + timedelta(hours=random.randint(1,100)) for d in opened_dates],\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# --- Chatbot Function (CSV + RAG) ---\n",
    "def chatbot_fn(message, history):\n",
    "    history = history or []\n",
    "\n",
    "    # CSV command\n",
    "    if \"create csv\" in message.lower():\n",
    "        df = generate_servicenow_data(10000)\n",
    "        tmp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".csv\")\n",
    "        df.to_csv(tmp_file.name, index=False)\n",
    "\n",
    "        preview = df.head().to_markdown()\n",
    "        bot_reply = f\"Hereâ€™s a preview of the dataset:\\n\\n{preview}\"\n",
    "        history.append((message, bot_reply))\n",
    "        history.append((\"\", (tmp_file.name, \"ðŸ“‚ Download ServiceNow CSV (10k rows)\")))\n",
    "        return history, \"\"\n",
    "\n",
    "    # Otherwise â†’ run RAG\n",
    "    rag_result = rag_chain({\"question\": message})\n",
    "    reply = rag_result[\"answer\"]\n",
    "\n",
    "    history.append((message, reply))\n",
    "    return history, \"\"\n",
    "\n",
    "# --- Gradio App ---\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(label=\"ServiceNow Assistant (CSV + RAG)\", height=500)\n",
    "    msg = gr.Textbox(\n",
    "        label=\"Ask me something\",\n",
    "        placeholder=\"Type 'create csv' to generate a dataset, or ask a question from your documents...\",\n",
    "    )\n",
    "\n",
    "    msg.submit(chatbot_fn, [msg, chatbot], [chatbot, msg])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea2623a0-d5a0-425c-b4d9-53666697bb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_11812\\2233931995.py:109: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  rag_result = rag_chain({\"question\": message})\n"
     ]
    }
   ],
   "source": [
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a923971-8d1a-48ed-9276-274525acd413",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
