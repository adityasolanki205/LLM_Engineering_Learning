{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aa7ea38-bf6d-4d3d-af96-29f354693ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import google.generativeai\n",
    "import anthropic\n",
    "import gradio as gr # oh yeah!\n",
    "import pandas as pd\n",
    "import io\n",
    "# imports\n",
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "# imports for langchain, plotly and Chroma\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader,  PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.callbacks import StdOutCallbackHandler\n",
    "import gradio as gr\n",
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import random\n",
    "import tempfile\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d272696-c185-4db2-a2ea-39ecbeda1305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Google API Key exists and begins AIzaSyAt\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "968e62bf-7a4d-4939-85ab-9a7148adc10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()\n",
    "\n",
    "google.generativeai.configure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b310360e-a0c0-4f76-87a7-fd72bb3f67b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4o-mini\"\n",
    "db_name = \"vector_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62453731-54e0-4edd-84d8-411b3bf30096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 210 documents\n"
     ]
    }
   ],
   "source": [
    "folders = glob.glob(\"pdf/*.pdf\")\n",
    "\n",
    "documents = []\n",
    "\n",
    "for folder in folders:\n",
    "    doc_type = os.path.splitext(os.path.basename(folder))[0]\n",
    "\n",
    "    # Load all PDFs inside this folder\n",
    "    loader = PyPDFLoader(folder)\n",
    "    folder_docs = loader.load()\n",
    "\n",
    "    # Attach folder name as metadata\n",
    "    for doc in folder_docs:\n",
    "        doc.metadata[\"doc_type\"] = doc_type\n",
    "        documents.append(doc)\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc39d1b1-f71a-4f0d-9439-8ebcbaca6498",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folders = glob.glob(\"knowledge-base/*\")\n",
    "\n",
    "text_loader_kwargs = {'encoding': 'utf-8'}\n",
    "\n",
    "#documents = []\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "    loader = DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\n",
    "    folder_docs = loader.load()\n",
    "    for doc in folder_docs:\n",
    "        doc.metadata[\"doc_type\"] = doc_type\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a97ab40b-9e72-4e49-961d-126150a1f3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1088, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0cad94f-7f62-4a8e-899c-1dc32408db9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 241 documents\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loaded {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2fba7bb-aba8-4e0d-80f5-b3b6c4c62072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='89\n",
      "IIMA HR Policy Manual 2023\n",
      "4. Financial upgradation under the scheme shall be allowed in the immediate next higher level \n",
      "pay in the hierarchy of revised levels as per the policy of the Institute.\n",
      "5. Financial upgradation would be on non-functional basis (i.e. Group D employee is categorised \n",
      "as Group D only) subject to eligibility and within the Group. \n",
      "6. As such there shall be no additional financial upgradation for the senior employee on the \n",
      "ground that the junior employee in the level has got higher pay under the Scheme. If the \n",
      "senior employee remains on LWP or/and does not enhance the education qualification, then \n",
      "possible that a junior employee may get an advantage compared to a senior employee.\n",
      "7. Following are the existing Level change in the Institute for Group D employees:\n",
      "Sr. Level Type of \n",
      "Promotion Minimum service in the Institute (from DOJ)\n",
      "1 1 -- Entry\n",
      "2 2 SP #1 10 years\n",
      "3 3 SP #2 20 years\n",
      "4 4 SR #1 27 years\n",
      "5 5 SR #2 33/35 years (33 years to be considered, in case \n",
      "employee is retiring in the year immediate after \n",
      "review period/year).\n",
      "5. PROMOTION POLICY FOR EXISTING GROUP D EMPLOYEES TO GROUP C \n",
      "(PROMOTION WITH GROUP CHANGE) AT ONE LEVEL HIGHER IN GROUP C \n",
      "TO THE CURRENT LEVEL IN GROUP D:\n",
      "1. Methodology: Written Test and Interview.\n",
      "2. Eligibility: Group D employee of IIMA,,\n",
      "i. with minimum graduation from a recognised university at the time of review,\n",
      "ii. minimum service of 5 years,\n",
      "iii. with “very good” remarks in the Performance Evaluation Reports during last \n",
      "five years.\n",
      "iv. fulfilling all other financial upgradation/ promotion criteria.\n",
      "3. Syllabus: The syllabus of the written test may be as follows:\n",
      "Sr. Topic Marks\n",
      "1 General English (Written and Spoken – equivalent to SCOPE \n",
      "syllabus defined by Government of Gujarat) – Lower English\n",
      "30\n",
      "3 Computer awareness (MS-Office-Word, Excel, Power Point, Internet, \n",
      "E-Mail) equivalent to CCC of Govt.of Gujarat \n",
      "25\n",
      "4 Numerical ability (similar to Bank’s clerk examination) 15\n",
      "5 Reasoning ability (similar to Bank’s clerk examination) 15\n",
      "6 General awareness (similar to Bank’s clerk examination) 15\n",
      "Total 100' metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 18.1 (Windows)', 'creationdate': '2023-01-27T09:40:38+05:30', 'moddate': '2023-01-27T09:40:47+05:30', 'trapped': '/False', 'source': 'pdf\\\\HR Policy Manual 2023.pdf', 'total_pages': 208, 'page': 98, 'page_label': '89', 'doc_type': 'HR Policy Manual 2023'}\n"
     ]
    }
   ],
   "source": [
    "print (chunks[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a76a678-a1ef-4a1d-9127-38727d2d921b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created with 333 documents\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "059fe893-c783-4d6f-adf1-27aa3d1f7d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vectors have 1,536 dimensions\n"
     ]
    }
   ],
   "source": [
    "collection = vectorstore._collection\n",
    "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "dimensions = len(sample_embedding)\n",
    "print(f\"The vectors have {dimensions:,} dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a761c721-01bc-46e1-af43-dc6d59674392",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_9656\\2062993249.py:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "# Let's investigate what gets sent behind the scenes\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.5, model_name=MODEL)\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
    "\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory, callbacks=[StdOutCallbackHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3390059c-84b7-4486-a5f5-9870c20e8e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_9656\\2761077405.py:101: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(label=\"ServiceNow Chatbot\", height=500)\n"
     ]
    }
   ],
   "source": [
    "def generate_servicenow_data(n=10000):\n",
    "    np.random.seed(42)\n",
    "    random.seed(42)\n",
    "\n",
    "    priorities = [\"Low\", \"Medium\", \"High\", \"Critical\"]\n",
    "    impacts = [\"Low\", \"Medium\", \"High\"]\n",
    "    urgencies = [\"Low\", \"Medium\", \"High\"]\n",
    "    statuses = [\"Open\", \"In Progress\", \"Resolved\", \"Closed\"]\n",
    "    categories = [\"Network\", \"Software\", \"Hardware\", \"Database\", \"Security\"]\n",
    "    subcategories = {\n",
    "        \"Network\": [\"VPN\", \"LAN\", \"WAN\"],\n",
    "        \"Software\": [\"Email\", \"OS\", \"Application\"],\n",
    "        \"Hardware\": [\"Laptop\", \"Desktop\", \"Printer\"],\n",
    "        \"Database\": [\"Oracle\", \"MySQL\", \"SQL Server\"],\n",
    "        \"Security\": [\"Phishing\", \"Malware\", \"Access\"],\n",
    "    }\n",
    "    resolution_codes = [\"Solved Remotely\", \"Solved via On-Site\", \"Workaround Provided\", \"Not Reproducible\"]\n",
    "\n",
    "   # Base dates\n",
    "    opened_dates = pd.date_range(\"2025-07-01\", periods=n, freq=\"h\")\n",
    "\n",
    "    # Random statuses\n",
    "    status_selected = np.random.choice(statuses, n, p=[0.3, 0.3, 0.2, 0.2])  # 60% still open/in progress\n",
    "\n",
    "    closed_dates = []\n",
    "    resolution_codes_selected = []\n",
    "    resolved_by = []\n",
    "\n",
    "    for i, status in enumerate(status_selected):\n",
    "        if status in [\"Resolved\", \"Closed\"]:\n",
    "            closed_dt = opened_dates[i] + timedelta(hours=random.randint(1, 72))\n",
    "            closed_dates.append(closed_dt)\n",
    "            resolution_codes_selected.append(random.choice(resolution_codes))\n",
    "            resolved_by.append(f\"user{random.randint(401,600)}\")\n",
    "        else:\n",
    "            closed_dates.append(pd.NaT)  # no close date\n",
    "            resolution_codes_selected.append(None)\n",
    "            resolved_by.append(None)\n",
    "\n",
    "    categories_selected = np.random.choice(categories, n)\n",
    "    subcategories_selected = [random.choice(subcategories[cat]) for cat in categories_selected]\n",
    "\n",
    "    data = {\n",
    "        \"Incident_ID\": [f\"INC{i:06d}\" for i in range(1, n+1)],\n",
    "        \"Opened_At\": opened_dates,\n",
    "        \"Closed_At\": closed_dates,\n",
    "        \"Opened_By\": [f\"user{random.randint(1,200)}\" for _ in range(n)],\n",
    "        \"Assigned_To\": [f\"user{random.randint(201,400)}\" for _ in range(n)],\n",
    "        \"Priority\": np.random.choice(priorities, n),\n",
    "        \"Impact\": np.random.choice(impacts, n),\n",
    "        \"Urgency\": np.random.choice(urgencies, n),\n",
    "        \"Category\": categories_selected,\n",
    "        \"Subcategory\": subcategories_selected,\n",
    "        \"Status\": status_selected,\n",
    "        \"Resolution_Code\": resolution_codes_selected,\n",
    "        \"Resolved_By\": resolved_by,\n",
    "        \"Short_Description\": [f\"Issue {i} - {random.choice(categories)} related\" for i in range(1, n+1)],\n",
    "        \"Description\": [f\"Detailed description of incident {i}, auto-generated for testing.\" for i in range(1, n+1)],\n",
    "        \"Updated_At\": [d + timedelta(hours=random.randint(1,100)) for d in opened_dates],\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "def chatbot_fn(message, history):\n",
    "    history = history or []\n",
    "\n",
    "    if \"create csv\" in message.lower():\n",
    "        df = generate_servicenow_data(10000)\n",
    "        tmp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".csv\")\n",
    "        csv_path = \"servicenow_dataset.csv\"\n",
    "        df.to_csv(tmp_file.name, index=False)\n",
    "    \n",
    "        # reply: preview + file download\n",
    "        preview = df.head().to_markdown()\n",
    "        bot_reply = f\"Here’s a preview of the dataset:\\n\\n{preview}\"\n",
    "\n",
    "        history.append((message, bot_reply))\n",
    "        history.append((\"\", (csv_path, \"📂 Download ServiceNow CSV (10k rows)\")))\n",
    "\n",
    "        return history, \"\" \n",
    "    \n",
    "    result = conversation_chain.invoke({\"question\": message})\n",
    "    history.append((message,  result[\"answer\"]))\n",
    "    return history, \"\"  # clear input\n",
    "\n",
    "\n",
    "# Gradio UI\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(label=\"ServiceNow Chatbot\", height=500)\n",
    "    msg = gr.Textbox(\n",
    "        label=\"Type your message here\",\n",
    "        placeholder=\"Ask me something or type 'create csv'...\",\n",
    "    )\n",
    "\n",
    "    msg.submit(chatbot_fn, [msg, chatbot], [chatbot, msg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73eee953-c85a-4670-b2e6-c606a70e2437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question.\n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "39\n",
      "IIMA HR Policy Manual 2023\n",
      "DECLARATION\n",
      "I, hereby declare that the information provided by me to the \n",
      "institute in my job application and thereafter is correct to the best \n",
      "of my knowledge and belief. If anything found incorrect or has \n",
      "any discrepancies, the institute has the right to terminate my \n",
      "appointment at any given time without assigning any reason.  I \n",
      "also know that providing wrong/fake information or certificate to \n",
      "the institute is punishable under court of law.\n",
      "        \n",
      "(Name & Signature) \n",
      "Place: Ahmedabad\n",
      "Date:\n",
      "\n",
      "40\n",
      "IIMA HR Policy Manual 2023\n",
      "JOINING REPORT\n",
      "To \n",
      "Associate Vice President-HR \n",
      "IIM Ahmedabad\n",
      "Through: \n",
      "Dear Sir\n",
      "Thank you very much for your letter appointing me to the post of _____________________________\n",
      "in this Institute.  I accept the terms and conditions mentioned therein.\n",
      "I am joining my duties at the Institute today, i.e. _________________________________ (forenoon)\n",
      "Thank you,\n",
      "Yours faithfully,\n",
      "Signature:  ____________________________________\n",
      "Name       :  __________________________________\n",
      "Date      :  ________________________________\n",
      "\n",
      "ii\n",
      "IIMA HR Policy Manual 2023\n",
      "\n",
      "155\n",
      "IIMA HR Policy Manual 2023\n",
      "3. Please rate various aspects of the programme in general: -\n",
      "5\n",
      "Excellent\n",
      "4\n",
      "V. Good\n",
      "3\n",
      "Good\n",
      "2\n",
      "Average\n",
      "1\n",
      "Poor\n",
      "Usefulness of Training in \n",
      "my work\n",
      "Information on course \n",
      "contents\n",
      "Relevance to  \n",
      "Quality of Course Material\n",
      "Preparation by HODs\n",
      "Level of Interaction\n",
      "Overall Learning from  \n",
      "training\n",
      "4. How will it be useful in your work? (give specific examples)\n",
      "5. Any Suggestions/Comments/Areas of improvement*:\n",
      "     * In case of more comments use back side of this sheet\n",
      " Date : _________  Signature of participant : __________________\n",
      "\n",
      "32\n",
      "IIMA HR Policy Manual 2023\n",
      "Instructions:\n",
      "(Please read the following instructions carefully before filling in the form)\n",
      "a) The form is to be filled in his/her own handwriting\n",
      "b) Please attach photocopies of relevant certificates to the extent conveniently possible.\n",
      "I. PERSONAL DATA\n",
      "Name in full (IN BLOCK LETTERS)\n",
      "First name _________________________________ Middle _______________________________\n",
      "Surname _______________________________________________________________________\n",
      "Parent’s Name ( Specify Whether Mother/Father) :\n",
      "Spouse’s name :\n",
      "Change in name if any and reason thereof :\n",
      "Present Address : Permanent Address:\n",
      "Landline : Landline :\n",
      "Mobile : Mobile :\n",
      "Emergency Contact No: Email:\n",
      "Please attach Rent Agreement if not staying in own house:\n",
      "Date of Birth :      Age : Height : Weight :\n",
      "Identification marks:\n",
      "1)\n",
      "2)\n",
      "Place of Birth : State Gender :\n",
      "Religion*: Caste* : Sub Caste* : Blood Group* :\n",
      "Whether Minority* :\n",
      "Physically Challenged (Orthopedically/ Visually/Hearing Impaired), “ if yes then %thereof” :\n",
      "*This data is requested as per Government of India norms.\n",
      "Do you belong to Scheduled Caste/Tribe/OBC/PH/Gen ?  Yes/No\n",
      "(If yes, please attach certificate to that effect.)\n",
      "\n",
      "35\n",
      "IIMA HR Policy Manual 2023\n",
      "V.  Awards/ Honours if any:\n",
      "VI. PROFESSIONAL MEMBERSHIP\n",
      "     Please give details of membership of academic/professional/other organization.\n",
      "Organization Nature of Membership\n",
      "VII. REFERENCES : (Give names and particulars of Two prominent persons who may be \n",
      "approached for opinion about your candidature.  The referees should not be related to you, and \n",
      "should have known to you personally (eg teacher, employer, immediate supervisor)\n",
      "1) Name : 2) Name : \n",
      "         Designation :          Designation :\n",
      "         Address:          Address:\n",
      "         Contact No:\n",
      "         Email id :\n",
      "         Contact No:\n",
      "         Email id :\n",
      "VII. FAMILY DETAILS : \n",
      "MARITAL STATUS :     Single              Married           Widow           Widower        Divorcee \n",
      "Name  Date of Birth/Age Occupation Income\n",
      "(1) Spouse \n",
      "(2) Children (If any) 1)\n",
      "2)\n",
      "(3) Father\n",
      "(4) Mother\n",
      "(5) Brother / Sister\n",
      "(6) Other Family \n",
      "Member\n",
      "\n",
      "## Other HR Notes\n",
      "- Jordan has shown an interest in continuing education, actively participating in company-sponsored sales webinars.  \n",
      "- Notable for involvement in the Insurellm volunteer program, assisting local charity events related to financial literacy.  \n",
      "- Employee wellness advocate, consistently promotes team bonding activities and stress-relief workshops.  \n",
      "- Plans to enroll in a course for advanced sales strategies in Q4 2023, aiming to further enhance his skills at Insurellm.\n",
      "\n",
      "129\n",
      "IIMA HR Policy Manual 2023\n",
      "INDIAN INSTITUTE OF MANAGEMENT,Vastrapur Ahmedadad - 380 015.\n",
      "\n",
      "b\n",
      "IIMA HR Policy Manual 2023\n",
      "\n",
      "**Belvedere Insurance**  \n",
      "Signature: ______________________  \n",
      "Name: [Authorized Signatory]  \n",
      "Title: [Title]  \n",
      "Date: ______________________  \n",
      "\n",
      "--- \n",
      "This synthetic contract document outlines a fictional agreement between Insurellm and a fictional insurance client, Belvedere Insurance, which engages with the Markellm platform. The contract contains creative yet realistic terms for potential use in training and development in insurance technology scenarios.\n",
      "Human: Hi\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60653f07-8614-46b9-b8fb-3820dd6b18f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def chat(question, history):\n",
    "#     result = conversation_chain.invoke({\"question\": question})\n",
    "#     return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66bddce-aab4-4518-9db4-59cae07721a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # view = gr.ChatInterface(chat, type=\"messages\").launch(inbrowser=True)\n",
    "\n",
    "# prompts = [\n",
    "#     {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "#     {\"role\": \"user\", \"content\": \"Can you please create a test Dataset for me for Service now Incidents with few open and closed incidents and count ot be 10000 records\"}\n",
    "#   ]\n",
    "# system_message = \"You are a helpful assistant\"\n",
    "\n",
    "# def message_gpt(prompt):\n",
    "#     messages = [\n",
    "#         {\"role\": \"system\", \"content\": system_message},\n",
    "#         {\"role\": \"user\", \"content\": prompt}\n",
    "#       ]\n",
    "#     completion = openai.chat.completions.create(\n",
    "#         model='gpt-4o-mini',\n",
    "#         messages=messages,\n",
    "#     )\n",
    "#     csv_string =  completion.choices[0].message.content\n",
    "#     print (csv_string)\n",
    "#     return csv_string\n",
    "\n",
    "# def process_and_display_csv(prompt):\n",
    "#         csv_data = message_gpt(prompt)\n",
    "#         # Convert the CSV string to a DataFrame for better display or further processing\n",
    "#         try:\n",
    "#             df = pd.read_csv(io.StringIO(csv_data))\n",
    "#             return df\n",
    "#         except Exception as e:\n",
    "#             return f\"Error processing CSV: {e}\\nRaw CSV data:\\n{csv_data}\"\n",
    "\n",
    "# iface = gr.Interface(\n",
    "#     fn=process_and_display_csv,\n",
    "#     inputs=gr.Textbox(lines=5, label=\"Enter your prompt for CSV generation:\"),\n",
    "#     outputs=gr.Dataframe(label=\"Generated CSV Data\"), # Use gr.Dataframe to display tabular data\n",
    "#     title=\"GPT CSV Generator\"\n",
    "# )\n",
    "\n",
    "# iface.launch(share=False) # Set share=True to get a public link if needed\n",
    "\n",
    "# #gr.Interface(fn=message_gpt, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch(share=True)\n",
    "\n",
    "# import gradio as gr\n",
    "# import openai\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import io\n",
    "# import random\n",
    "# import tempfile\n",
    "# from datetime import timedelta\n",
    "\n",
    "# def chatbot_fn(message, history):\n",
    "#     history = history or []\n",
    "\n",
    "#     # special command: create dataset\n",
    "#     if \"create csv\" in message.lower():\n",
    "#         df = generate_servicenow_data(10000)\n",
    "#         csv_path = \"servicenow_dataset.csv\"\n",
    "#         df.to_csv(csv_path, index=False)\n",
    "#         history.append((message, (csv_path, \"📂 Download ServiceNow CSV (10k rows)\")))\n",
    "#         return history, \"\"  # clear input\n",
    "\n",
    "#     # otherwise, ask GPT\n",
    "#     completion = openai.chat.completions.create(\n",
    "#         model=\"gpt-4o-mini\",  # or \"gpt-4o\", adjust if needed\n",
    "#         messages=[{\"role\": \"system\", \"content\": \"You are a helpful ServiceNow assistant.\"}] +\n",
    "#                  [{\"role\": \"user\", \"content\": m[0]} for m in history if isinstance(m[0], str)] +\n",
    "#                  [{\"role\": \"assistant\", \"content\": m[1]} for m in history if isinstance(m[1], str)] +\n",
    "#                  [{\"role\": \"user\", \"content\": message}]\n",
    "#     )\n",
    "#     reply = completion.choices[0].message.content\n",
    "#     history.append((message, reply))\n",
    "#     return history, \"\"  # clear input\n",
    "\n",
    "# def generate_servicenow_data(n=10000):\n",
    "#     np.random.seed(42)\n",
    "#     random.seed(42)\n",
    "\n",
    "#     priorities = [\"Low\", \"Medium\", \"High\", \"Critical\"]\n",
    "#     impacts = [\"Low\", \"Medium\", \"High\"]\n",
    "#     urgencies = [\"Low\", \"Medium\", \"High\"]\n",
    "#     statuses = [\"Open\", \"In Progress\", \"Resolved\", \"Closed\"]\n",
    "#     categories = [\"Network\", \"Software\", \"Hardware\", \"Database\", \"Security\"]\n",
    "#     subcategories = {\n",
    "#         \"Network\": [\"VPN\", \"LAN\", \"WAN\"],\n",
    "#         \"Software\": [\"Email\", \"OS\", \"Application\"],\n",
    "#         \"Hardware\": [\"Laptop\", \"Desktop\", \"Printer\"],\n",
    "#         \"Database\": [\"Oracle\", \"MySQL\", \"SQL Server\"],\n",
    "#         \"Security\": [\"Phishing\", \"Malware\", \"Access\"],\n",
    "#     }\n",
    "#     resolution_codes = [\"Solved Remotely\", \"Solved via On-Site\", \"Workaround Provided\", \"Not Reproducible\"]\n",
    "\n",
    "#    # Base dates\n",
    "#     opened_dates = pd.date_range(\"2025-07-01\", periods=n, freq=\"h\")\n",
    "\n",
    "#     # Random statuses\n",
    "#     status_selected = np.random.choice(statuses, n, p=[0.3, 0.3, 0.2, 0.2])  # 60% still open/in progress\n",
    "\n",
    "#     closed_dates = []\n",
    "#     resolution_codes_selected = []\n",
    "#     resolved_by = []\n",
    "\n",
    "#     for i, status in enumerate(status_selected):\n",
    "#         if status in [\"Resolved\", \"Closed\"]:\n",
    "#             closed_dt = opened_dates[i] + timedelta(hours=random.randint(1, 72))\n",
    "#             closed_dates.append(closed_dt)\n",
    "#             resolution_codes_selected.append(random.choice(resolution_codes))\n",
    "#             resolved_by.append(f\"user{random.randint(401,600)}\")\n",
    "#         else:\n",
    "#             closed_dates.append(pd.NaT)  # no close date\n",
    "#             resolution_codes_selected.append(None)\n",
    "#             resolved_by.append(None)\n",
    "\n",
    "#     categories_selected = np.random.choice(categories, n)\n",
    "#     subcategories_selected = [random.choice(subcategories[cat]) for cat in categories_selected]\n",
    "\n",
    "#     data = {\n",
    "#         \"Incident_ID\": [f\"INC{i:06d}\" for i in range(1, n+1)],\n",
    "#         \"Opened_At\": opened_dates,\n",
    "#         \"Closed_At\": closed_dates,\n",
    "#         \"Opened_By\": [f\"user{random.randint(1,200)}\" for _ in range(n)],\n",
    "#         \"Assigned_To\": [f\"user{random.randint(201,400)}\" for _ in range(n)],\n",
    "#         \"Priority\": np.random.choice(priorities, n),\n",
    "#         \"Impact\": np.random.choice(impacts, n),\n",
    "#         \"Urgency\": np.random.choice(urgencies, n),\n",
    "#         \"Category\": categories_selected,\n",
    "#         \"Subcategory\": subcategories_selected,\n",
    "#         \"Status\": status_selected,\n",
    "#         \"Resolution_Code\": resolution_codes_selected,\n",
    "#         \"Resolved_By\": resolved_by,\n",
    "#         \"Short_Description\": [f\"Issue {i} - {random.choice(categories)} related\" for i in range(1, n+1)],\n",
    "#         \"Description\": [f\"Detailed description of incident {i}, auto-generated for testing.\" for i in range(1, n+1)],\n",
    "#         \"Updated_At\": [d + timedelta(hours=random.randint(1,100)) for d in opened_dates],\n",
    "#     }\n",
    "\n",
    "#     return pd.DataFrame(data)\n",
    "# def chatbot_fn(message, history):\n",
    "#     history = history or []\n",
    "\n",
    "#     if \"create csv\" in message.lower():\n",
    "#         df = generate_servicenow_data(10000)\n",
    "#         tmp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".csv\")\n",
    "#         csv_path = \"servicenow_dataset.csv\"\n",
    "#         df.to_csv(tmp_file.name, index=False)\n",
    "    \n",
    "#         # reply: preview + file download\n",
    "#         preview = df.head().to_markdown()\n",
    "#         bot_reply = f\"Here’s a preview of the dataset:\\n\\n{preview}\"\n",
    "\n",
    "#         history.append((message, bot_reply))\n",
    "#         history.append((\"\", (csv_path, \"📂 Download ServiceNow CSV (10k rows)\")))\n",
    "\n",
    "#         return history, \"\"  # clear input\n",
    "\n",
    "\n",
    "#     # otherwise, ask GPT\n",
    "#     completion = openai.chat.completions.create(\n",
    "#         model=\"gpt-4o-mini\",  # or \"gpt-4o\", adjust if needed\n",
    "#         messages=[{\"role\": \"system\", \"content\": \"You are a helpful ServiceNow assistant.\"}] +\n",
    "#                  [{\"role\": \"user\", \"content\": m[0]} for m in history if isinstance(m[0], str)] +\n",
    "#                  [{\"role\": \"assistant\", \"content\": m[1]} for m in history if isinstance(m[1], str)] +\n",
    "#                  [{\"role\": \"user\", \"content\": message}]\n",
    "#     )\n",
    "#     reply = completion.choices[0].message.content\n",
    "#     history.append((message, reply))\n",
    "#     return history, \"\"  # clear input\n",
    "\n",
    "\n",
    "# # Gradio UI\n",
    "# with gr.Blocks() as demo:\n",
    "#     chatbot = gr.Chatbot(label=\"ServiceNow Chatbot\", height=500)\n",
    "#     msg = gr.Textbox(\n",
    "#         label=\"Type your message here\",\n",
    "#         placeholder=\"Ask me something or type 'create csv'...\",\n",
    "#     )\n",
    "\n",
    "#     msg.submit(chatbot_fn, [msg, chatbot], [chatbot, msg])\n",
    "\n",
    "# demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b034ce1-a846-41b0-aa5a-aa32b8d66d26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
