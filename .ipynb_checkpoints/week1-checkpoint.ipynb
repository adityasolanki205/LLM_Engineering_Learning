{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3c1ee05-ab39-4450-89b8-e7b2c4238299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d72a81fc-5a07-4cca-aee1-c9cc3abb2baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afe30bd1-2a0f-4f05-9f3a-4897e50dae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ab2d38e-91fc-4007-890a-2d93f7c9f85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! Welcome! It's great to hear from you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "message = \"Hello, GPT! This is my first ever message to you! Hi!\"\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=[{\"role\":\"user\", \"content\":message}])\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f46ce8da-b632-4cc1-9888-24484a34c531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "# If you're not familiar with Classes, check out the \"Intermediate Python\" notebook\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c348c56f-a140-4d32-b78e-0fdbaa423b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home - Edward Donner\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Well, hi there.\n",
      "I’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\n",
      "very\n",
      "amateur) and losing myself in\n",
      "Hacker News\n",
      ", nodding my head sagely to things I only half understand.\n",
      "I’m the co-founder and CTO of\n",
      "Nebula.io\n",
      ". We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\n",
      "acquired in 2021\n",
      ".\n",
      "We work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\n",
      "patented\n",
      "our matching model, and our award-winning platform has happy customers and tons of press coverage.\n",
      "Connect\n",
      "with me for more!\n",
      "May 28, 2025\n",
      "Connecting my courses – become an LLM expert and leader\n",
      "May 18, 2025\n",
      "2025 AI Executive Briefing\n",
      "April 21, 2025\n",
      "The Complete Agentic AI Engineering Course\n",
      "January 23, 2025\n",
      "LLM Workshop – Hands-on with Agents – resources\n",
      "Navigation\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Get in touch\n",
      "ed [at] edwarddonner [dot] com\n",
      "www.edwarddonner.com\n",
      "Follow me\n",
      "LinkedIn\n",
      "Twitter\n",
      "Facebook\n",
      "Subscribe to newsletter\n",
      "Type your email…\n",
      "Subscribe\n"
     ]
    }
   ],
   "source": [
    "# Let's try one out. Change the website and add print statements to follow along.\n",
    "\n",
    "ed = Website(\"https://edwarddonner.com\")\n",
    "print(ed.title)\n",
    "print(ed.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3272478-2efe-4ede-80ab-44d7e66b8ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69e5b970-74ad-4ff5-b24c-aeef2218ea4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e28cdfa-f972-4d04-8b93-1e5346f47499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are looking at a website titled Home - Edward Donner\n",
      "The contents of this website is as follows; please provide a short summary of this website in markdown. If it includes news or announcements, then summarize these too.\n",
      "\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Well, hi there.\n",
      "I’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\n",
      "very\n",
      "amateur) and losing myself in\n",
      "Hacker News\n",
      ", nodding my head sagely to things I only half understand.\n",
      "I’m the co-founder and CTO of\n",
      "Nebula.io\n",
      ". We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\n",
      "acquired in 2021\n",
      ".\n",
      "We work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\n",
      "patented\n",
      "our matching model, and our award-winning platform has happy customers and tons of press coverage.\n",
      "Connect\n",
      "with me for more!\n",
      "May 28, 2025\n",
      "Connecting my courses – become an LLM expert and leader\n",
      "May 18, 2025\n",
      "2025 AI Executive Briefing\n",
      "April 21, 2025\n",
      "The Complete Agentic AI Engineering Course\n",
      "January 23, 2025\n",
      "LLM Workshop – Hands-on with Agents – resources\n",
      "Navigation\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Get in touch\n",
      "ed [at] edwarddonner [dot] com\n",
      "www.edwarddonner.com\n",
      "Follow me\n",
      "LinkedIn\n",
      "Twitter\n",
      "Facebook\n",
      "Subscribe to newsletter\n",
      "Type your email…\n",
      "Subscribe\n"
     ]
    }
   ],
   "source": [
    "print(user_prompt_for(ed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fc19bcc-3863-4670-a7b0-1a10f02b7fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a snarky assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 2 + 2?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03b7e717-8fba-40a8-b147-c5b3f0ed1eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, let me grab my calculator for that one... Just kidding! It’s 4. Math wizardry at its finest!\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d6f2713-39ba-4e53-89e1-7874fe9ef840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-C7iMqTYDSdJbXCAq2VFR9w0C7BLbX', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Oh, let me grab my calculator for that one... Just kidding! It’s 4. Math wizardry at its finest!', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1755954880, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=26, prompt_tokens=26, total_tokens=52, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fd110ff-810e-45fb-aa46-c17fd972fc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "832072d7-53e8-4899-bf4a-6c9085fc4b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an assistant that analyzes the contents of a website and provides a short summary, ignoring text that might be navigation related. Respond in markdown.'},\n",
       " {'role': 'user',\n",
       "  'content': 'You are looking at a website titled Home - Edward Donner\\nThe contents of this website is as follows; please provide a short summary of this website in markdown. If it includes news or announcements, then summarize these too.\\n\\nHome\\nConnect Four\\nOutsmart\\nAn arena that pits LLMs against each other in a battle of diplomacy and deviousness\\nAbout\\nPosts\\nWell, hi there.\\nI’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\\nvery\\namateur) and losing myself in\\nHacker News\\n, nodding my head sagely to things I only half understand.\\nI’m the co-founder and CTO of\\nNebula.io\\n. We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\\nacquired in 2021\\n.\\nWe work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\\npatented\\nour matching model, and our award-winning platform has happy customers and tons of press coverage.\\nConnect\\nwith me for more!\\nMay 28, 2025\\nConnecting my courses – become an LLM expert and leader\\nMay 18, 2025\\n2025 AI Executive Briefing\\nApril 21, 2025\\nThe Complete Agentic AI Engineering Course\\nJanuary 23, 2025\\nLLM Workshop – Hands-on with Agents – resources\\nNavigation\\nHome\\nConnect Four\\nOutsmart\\nAn arena that pits LLMs against each other in a battle of diplomacy and deviousness\\nAbout\\nPosts\\nGet in touch\\ned [at] edwarddonner [dot] com\\nwww.edwarddonner.com\\nFollow me\\nLinkedIn\\nTwitter\\nFacebook\\nSubscribe to newsletter\\nType your email…\\nSubscribe'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_for(ed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2165d514-4b49-4ff2-b1c7-a5f688238f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model = \"gpt-4o-mini\",\n",
    "        messages = messages_for(website)\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c03424e-1ec7-4ccd-88bd-892115f2ce8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Summary of Edward Donner\\'s Website\\n\\nEdward Donner\\'s website showcases his passion for coding and experimentation with large language models (LLMs). He is the co-founder and CTO of Nebula.io, a company dedicated to utilizing AI to improve talent discovery and management. Previously, he founded and led untapt, an AI startup that was acquired in 2021. The platform and its proprietary LLMs have garnered significant attention and have positive customer feedback.\\n\\n## News and Announcements\\n- **May 28, 2025**: Announcement of courses aimed at helping individuals become experts and leaders in LLMs.\\n- **May 18, 2025**: Hosting an AI Executive Briefing event.\\n- **April 21, 2025**: Launching \"The Complete Agentic AI Engineering Course.\"\\n- **January 23, 2025**: Offering resources for a hands-on LLM workshop focusing on agents. \\n\\nThe website encourages connections with Edward and provides various channels for engagement.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad2411e1-54ac-4061-a83b-c1b32aee3185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b2c6268-d7a4-4a16-8a49-ffe84a14389f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Summary of Edward Donner's Website\n",
       "\n",
       "The website belongs to Ed, a co-founder and CTO of Nebula.io, where he focuses on applying AI to enhance talent discovery and engagement. Ed shares a personal interest in coding, experimenting with large language models (LLMs), and DJing, along with a passion for electronic music.\n",
       "\n",
       "## Key Features:\n",
       "- **Nebula.io:** The company specializes in using proprietary LLMs to match talent and has received patents and awards for its platform.\n",
       "- **Background:** Ed previously founded an AI startup called untapt, which was acquired in 2021.\n",
       "\n",
       "## Announcements:\n",
       "- **Courses and Workshops:**\n",
       "  - **May 28, 2025:** Announcement for connecting courses to become an expert in LLMs.\n",
       "  - **May 18, 2025:** Information about the 2025 AI Executive Briefing.\n",
       "  - **April 21, 2025:** Launch of \"The Complete Agentic AI Engineering Course.\"\n",
       "  - **January 23, 2025:** A workshop focused on hands-on experience with agents and related resources.\n",
       "\n",
       "Ed encourages visitors to connect with him, indicating his desire to engage with others interested in LLM technology and AI."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1715a5a3-1503-4291-8335-c0eee51fd31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Summary of CNN Website Content\n",
       "\n",
       "CNN is a leading news website that provides breaking news, video content, and in-depth analysis across a wide range of topics, including:\n",
       "\n",
       "- **Current Affairs:** Updates on ongoing global issues such as the Ukraine-Russia War and the Israel-Hamas conflict.\n",
       "- **US News:** Significant events like the recent bus crash in New York resulting in fatalities, and discussions concerning U.S. immigration with reports on ICE arrests.\n",
       "- **Health and Science:** Coverage on health issues, including a look into drowning prevention and innovations in technology such as the latest SpaceX Starship test.\n",
       "- **Business and Economics:** Insights on market trends and U.S. Federal Reserve policies, indicating potential rate cuts.\n",
       "- **Entertainment:** Celebrity news and cultural discussions, including the popularity of K-Pop and developments in television and film.\n",
       "\n",
       "## Recent Highlights:\n",
       "- **Famine in Gaza City:** There are reports confirming a severe famine situation in Gaza City.\n",
       "- **Ghislaine Maxwell Interview:** Highlights from her recent DOJ interview suggest potentially significant revelations concerning Jeffrey Epstein.\n",
       "- **Legal Affairs:** The conviction of a UK trans woman for sexual assault and the trial of an individual linked to a contract killing in the U.S.\n",
       "\n",
       "This platform also emphasizes user interaction, soliciting feedback on ad relevance and user experience. CNN presents news across multiple mediums, including video and audio, catering to diverse preferences for consuming information."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://cnn.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49df9c4c-1dea-4ebd-a607-785c506350bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "911309e8-e612-486a-9951-b7da55a06532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error you're encountering indicates that the model you're trying to run with Ollama requires more memory (RAM) than your system has available. In this case, the model needs approximately 12.9 GiB of RAM, while your laptop has only 10.8 GiB available.\n",
      "\n",
      "Here are a few possible solutions to resolve this issue:\n",
      "\n",
      "1. **Close Unnecessary Applications**: Make sure to close any applications or background processes that are consuming memory. This can free up RAM for Ollama.\n",
      "\n",
      "2. **Use a Smaller Model**: If you have the option to choose between multiple models, consider using a smaller model that requires less memory.\n",
      "\n",
      "3. **Increase Virtual Memory**: You can increase your system's virtual memory (paging file) which may help in some cases, but it won't be as effective as having physical RAM.\n",
      "\n",
      "4. **Upgrade RAM**: If possible, consider upgrading your laptop's RAM. This would be the most effective long-term solution if you plan on running memory-intensive applications frequently.\n",
      "\n",
      "5. **Cloud Solutions**: If upgrading hardware is not feasible, consider using cloud-based solutions or services that run these models remotely, thus sidestepping local hardware limitations.\n",
      "\n",
      "6. **Check for Memory Leaks or Issues**: Occasionally, software may be leaking memory or not releasing it when it's no longer needed. Make sure your system is updated, and if Ollama or the model had recent updates, consider rolling back or checking the documentation for any known issues.\n",
      "\n",
      "If you're consistently running into memory limitations with your current setups, a combination of the above suggestions may help effectively manage your needs.\n"
     ]
    }
   ],
   "source": [
    "message = \"I have ollama on my laptop. It was install yesterday. Now it is giving this error: Error 500 Internal Server Error: model requires more system memory (12.9 GiB) than is available (10.8 GiB)\"\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=[{\"role\":\"user\", \"content\":message}])\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15c8d26a-c8fa-42ef-b1c0-47bcd269bdc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Certainly! To create a DataFlow batch job that reads data from Google Cloud Storage (GCS) and writes it into BigQuery, you can use Apache Beam, which is the programming model behind Google Cloud Dataflow.\n",
       "\n",
       "Here’s a basic outline to get you started along with example code in Python:\n",
       "\n",
       "### Prerequisites\n",
       "1. **Google Cloud Account**: Ensure you have a Google Cloud project.\n",
       "2. **Enable APIs**: Enable the Dataflow API and BigQuery API.\n",
       "3. **Service Account**: Create a service account with permissions to access GCS and BigQuery, or use the project's default service account with appropriate permissions.\n",
       "4. **Apache Beam SDK**: Install the Apache Beam SDK for Python (or Java if you prefer).\n",
       "   ```bash\n",
       "   pip install apache-beam[gcp]\n",
       "   ```\n",
       "\n",
       "### Steps to Create a Dataflow Job\n",
       "\n",
       "1. **Create a GCS Bucket**: Upload your data files to a Google Cloud Storage bucket.\n",
       "2. **Define the Apache Beam Pipeline**: Create a pipeline that reads from GCS and writes to BigQuery.\n",
       "\n",
       "### Example Code\n",
       "\n",
       "Here’s a simple example using Python. This assumes you're reading a CSV file from GCS and writing it to BigQuery.\n",
       "\n",
       "```python\n",
       "import apache_beam as beam\n",
       "from apache_beam.options.pipeline_options import PipelineOptions, GoogleCloudOptions\n",
       "\n",
       "def run():\n",
       "    # Set your options\n",
       "    options = PipelineOptions()\n",
       "    gcp_options = options.view_as(GoogleCloudOptions)\n",
       "    gcp_options.project = 'your-gcp-project-id'  # Replace with your GCP project ID\n",
       "    gcp_options.job_name = 'example-dataflow-job'  # Replace with a unique job name\n",
       "    gcp_options.staging_location = 'gs://your-bucket-name/staging'  # Replace with your GCS staging bucket\n",
       "    gcp_options.temp_location = 'gs://your-bucket-name/temp'  # Replace with your GCS temp location\n",
       "    options.view_as(BeamOptions).runner = 'DataflowRunner'\n",
       "\n",
       "    # Define the schema for the BigQuery table\n",
       "    table_schema = {\n",
       "        'fields': [\n",
       "            {'name': 'field1', 'type': 'STRING'},\n",
       "            {'name': 'field2', 'type': 'INTEGER'},\n",
       "            # Add additional fields as necessary\n",
       "        ]\n",
       "    }\n",
       "\n",
       "    with beam.Pipeline(options=options) as p:\n",
       "        (p \n",
       "         | 'Read from GCS' >> beam.io.ReadFromText('gs://your-bucket-name/path/to/your/file.csv', skip_leading_rows=1)\n",
       "         | 'Convert to Dictionary' >> beam.Map(lambda line: dict(zip(['field1', 'field2'], line.split(','))))  # Adjust based on your CSV\n",
       "         | 'Write to BigQuery' >> beam.io.WriteToBigQuery(\n",
       "                'your-gcp-project-id:your_dataset.your_table',\n",
       "                schema=table_schema,\n",
       "                write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND)\n",
       "        )\n",
       "\n",
       "if __name__ == '__main__':\n",
       "    run()\n",
       "```\n",
       "\n",
       "### Notes:\n",
       "- Replace `your-gcp-project-id`, `your-bucket-name`, and `your_dataset.your_table` with your actual project ID, bucket name, and BigQuery table name.\n",
       "- The example expects a CSV file, so adjust the `Convert to Dictionary` logic based on the format of your input file.\n",
       "- The `WriteToBigQuery` function uses `WRITE_APPEND`, meaning it will append data to the existing table.\n",
       "\n",
       "### Running the Job\n",
       "You can run your Python script from the command line. Make sure you have authenticated Google Cloud SDK configured to your Google Cloud account.\n",
       "\n",
       "```bash\n",
       "python your_script.py\n",
       "```\n",
       "\n",
       "### Monitoring\n",
       "Once the job is submitted, you can monitor the job in the Google Cloud Console under Dataflow.\n",
       "\n",
       "### Additional Configuration\n",
       "Depending on the size of your data and the structure, you might want to configure additional options such as autoscaling, worker machine types, etc.\n",
       "\n",
       "This should give you a good starting point! Let me know if you have any questions or need further assistance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53f921ed-0280-419d-92cc-8d66d65a2c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Anthropic - Overview\n",
       "\n",
       "Anthropic is a research and product development company focused on creating AI technologies with safety as a core principle. Their flagship product, **Claude**, is designed to deliver advanced AI capabilities while prioritizing human benefit and responsible development.\n",
       "\n",
       "## Key Features\n",
       "\n",
       "- **Claude AI Models**: Includes the newest release, **Claude Opus 4.1**, and **Claude Sonnet 4**, which provide enhancements for coding and AI agent functionalities.\n",
       "- **API Services**: Developers can create custom AI-powered applications using the Claude API.\n",
       "- **Solutions for Various Sectors**: Tailored offerings for sectors like education, government, financial services, and customer support.\n",
       "\n",
       "## Recent Announcements\n",
       "\n",
       "- **ISO 42001 Certification**: Anthropic has achieved ISO 42001 certification, emphasizing its commitment to responsible AI development.\n",
       "- **Claude Opus 4.1 Launch**: Announced to be the most intelligent model yet, it enhances both coding and AI agent capabilities.\n",
       "- **Core Views on AI Safety**: Anthropic emphasizes the importance of responsible AI development, advocating for continuous learning and research in the field. \n",
       "\n",
       "## Additional Resources\n",
       "\n",
       "- **Anthropic Academy**: A resource for learning how to effectively build with Claude and implement its capabilities.\n",
       "- **Research Initiatives**: Ongoing projects and papers that address the societal impacts and safety concerns related to AI technologies. \n",
       "\n",
       "By focusing on the long-term well-being of humanity, Anthropic aims to set a standard for what responsible AI development should look like."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://anthropic.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "025db0e8-3041-460e-ba89-7f7ff9c8d51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72c61470-2741-415d-a865-49f02d0f0f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3:8b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49ff03c5-4b52-481e-9aec-1a56d5600768",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a01f1904-1209-490f-be3d-d63e950986b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cec038b-c57b-44a5-b89e-6dd1eb4e57b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print (response.json()['message']['content'])\n",
    "#print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98f72a5e-10fe-4f26-b44d-c0a858d2b404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Generation**: AI-powered content generation can create high-quality content, such as blog posts, product descriptions, social media posts, and more, reducing the need for human writers and saving time.\n",
      "2. **Customer Service Chatbots**: Generative AI can power chatbots that can understand customer queries, generate responses, and even escalate issues to human representatives when needed.\n",
      "3. **Marketing Automation**: AI-generated content can be used in marketing campaigns, such as creating personalized email newsletters, social media posts, and product recommendations based on customer behavior.\n",
      "4. **Data Analytics**: Generative AI can analyze large datasets and generate insights, patterns, and predictions, helping businesses make data-driven decisions.\n",
      "5. **Product Development**: AI-powered generative design tools can help designers create new products, improve existing ones, and optimize production processes.\n",
      "6. **Sales Forecasting**: Generative AI models can analyze sales data and generate predictions about future sales trends, helping businesses make informed inventory management and supply chain decisions.\n",
      "7. **Creative Writing**: AI-powered writing tools can assist in writing tasks such as composing emails, reports, and documents, freeing up human writers to focus on more creative tasks.\n",
      "8. **Audio and Video Generation**: Generative AI models can create high-quality audio and video content, such as music tracks, voiceovers, and explainer videos, reducing the need for human creatives.\n",
      "9. **Sentiment Analysis**: AI-powered sentiment analysis tools can generate insights about customer opinions, attitudes, and emotions, helping businesses improve their customer service and marketing strategies.\n",
      "10. **Cybersecurity**: Generative AI models can be used to detect and respond to cyber threats by generating fake data and simulating attacks, making it harder for hackers to identify real targets.\n",
      "11. **Supply Chain Optimization**: Generative AI models can optimize supply chain operations by predicting demand, identifying bottlenecks, and suggesting improvements in logistics and inventory management.\n",
      "12. **Financial Forecasting**: AI-powered financial forecasting tools can generate predictions about stock prices, currency exchange rates, and market trends, helping businesses make informed investment decisions.\n",
      "13. **Human Resources**: Generative AI models can assist in HR tasks such as generating job descriptions, interviewing candidates, and providing employee training and development recommendations.\n",
      "14. **IT Operations**: AI-powered IT operations tools can generate insights about system performance, detect anomalies, and suggest improvements in network management and infrastructure planning.\n",
      "15. **Research and Development**: Generative AI models can aid in R&D by generating hypotheses, testing theories, and identifying new opportunities for innovation.\n",
      "\n",
      "These are just a few examples of the many business applications of generative AI. As the technology continues to evolve, we can expect even more innovative uses cases to emerge across various industries.\n"
     ]
    }
   ],
   "source": [
    "print (response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec73918d-1d1e-4595-ad35-c9f4b9a9de24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Generation**: Generative AI can create high-quality content, such as articles, blog posts, social media posts, and even entire books. This technology can help businesses streamline their content creation process, saving time and resources.\n",
      "2. **Product Design**: Generative AI can be used to design new products or improve existing ones by generating multiple design options based on user preferences, market trends, and product requirements.\n",
      "3. **Customer Service Chatbots**: Generative AI-powered chatbots can engage with customers in a more human-like manner, providing personalized responses to common inquiries and freeing up human customer support agents for more complex issues.\n",
      "4. **Data Analysis and Visualization**: Generative AI can help analysts create interactive data visualizations, such as dashboards, reports, and infographics, making it easier to identify trends and patterns in large datasets.\n",
      "5. **Email Marketing Automation**: Generative AI-powered email marketing platforms can generate personalized emails, subject lines, and even entire email campaigns based on customer behavior, preferences, and demographics.\n",
      "6. **Predictive Maintenance**: Generative AI can analyze sensor data from equipment and machines to predict when maintenance is required, reducing downtime and increasing overall efficiency.\n",
      "7. **Market Research and Forecasting**: Generative AI can generate synthetic data sets that mimic real-world market conditions, allowing businesses to test hypotheses, simulate scenarios, and make more informed decisions.\n",
      "8. **Cybersecurity**: Generative AI-powered tools can detect and respond to cyber threats by generating customized signatures, rules, and alerts based on patterns in malware behavior and network traffic.\n",
      "9. **Supply Chain Optimization**: Generative AI can optimize supply chain operations by predicting demand, identifying bottlenecks, and recommending changes to logistics, inventory management, and sourcing strategies.\n",
      "10. **Personalized Marketing**: Generative AI-powered platforms can create personalized marketing messages, offers, and recommendations based on individual customer behavior, preferences, and demographics.\n",
      "11. **Financial Services**: Generative AI can help financial institutions generate synthetic data sets for stress testing, risk assessment, and compliance reporting, reducing the need for manual data entry and improving decision-making.\n",
      "12. **Healthcare**: Generative AI-powered platforms can assist in medical research by generating synthetic patient data, simulating clinical trials, and identifying potential treatments based on large datasets of medical records.\n",
      "13. **Real Estate**: Generative AI can help real estate companies generate virtual property tours, create 3D models of buildings, and predict market trends based on historical sales data and current market conditions.\n",
      "14. **HR and Recruitment**: Generative AI-powered platforms can assist in talent acquisition by generating job descriptions, interviewing candidates, and predicting job performance based on large datasets of employee information.\n",
      "\n",
      "These are just a few examples of the many business applications of generative AI. As the technology continues to evolve, we can expect to see even more innovative uses across various industries.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60500e8b-250c-4659-8a29-6a621eea1a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The exciting world of Generative AI! Here are some inspiring business applications:\n",
      "\n",
      "1. **Content Generation**: AI can generate high-quality content, such as blog posts, social media updates, and product descriptions, freeing up your human writers for more strategic tasks. This is especially useful for businesses with a large online presence.\n",
      "2. **Product Design**: Generative AI can aid in the design process by generating ideas, iterating on concepts, and creating prototypes. This helps designers work faster and smarter, while also reducing errors.\n",
      "3. **Customer Service Chatbots**: AI-powered chatbots can generate responses to customer inquiries, providing 24/7 support and resolving issues efficiently. This improves customer satisfaction and reduces support costs.\n",
      "4. **Marketing Campaigns**: Generative AI can help create personalized marketing campaigns by generating targeted ads, emails, and social media posts based on individual customer data.\n",
      "5. **Product Recommendations**: AI-driven recommendation engines generate product suggestions tailored to each customer's behavior, preferences, and purchase history. This leads to increased sales and improved customer satisfaction.\n",
      "6. **Data Analysis and Visualization**: Generative AI can analyze large datasets and create interactive visualizations, making complex data more accessible and understandable for business stakeholders.\n",
      "7. **Natural Language Processing (NLP)**: AI-powered NLP enables businesses to develop advanced chatbots, voice assistants, and sentiment analysis tools to better understand customer interactions.\n",
      "8. **Financial Forecasting**: Generative AI can analyze historical financial data and generate predictions about future trends, helping businesses make informed investment decisions or risk assessments.\n",
      "9. **Supply Chain Optimization**: AI-generated models can optimize logistics, inventory management, and demand forecasting, reducing costs, increasing efficiency, and improving supply chain resilience.\n",
      "10. **HR and Recruitment**: Generative AI can assist in screening resumes, generating interview questions, and predicting employee retention rates, streamlining the hiring process and minimizing biases.\n",
      "11. **Cybersecurity**: AI-generated models can detect anomalies, prevent attacks, and even predict potential security breaches, protecting businesses from costly cyber threats.\n",
      "12. **Real Estate and Property Development**: Generative AI can generate property valuations, assess market trends, and optimize property development strategies, helping businesses make informed decisions about investments or expansions.\n",
      "13. **Mergers and Acquisitions**: AI-powered due diligence tools can quickly analyze large amounts of data to identify potential merger or acquisition targets, reducing the time-to-market for new deals.\n",
      "14. **Virtual Assistants**: Generative AI is being used in various virtual assistant platforms, such as Google Assistant or Amazon Alexa, to provide users with personalized recommendations and control over smart devices.\n",
      "15. **Insurance and Risk Assessment**: AI-generated models can assess risk profiles, predict claim rates, and generate personalized insurance policies, helping businesses better manage claims and reduce costs.\n",
      "\n",
      "These are just a few examples of the many exciting business applications of Generative AI. As the technology continues to evolve, we can expect even more innovative use cases in various industries!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898c734c-96de-496b-98b0-1a5b90fb371d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
